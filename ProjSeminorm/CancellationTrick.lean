/-
Copyright (c) 2026 Tobias Osborne. All rights reserved.
Released under Apache 2.0 license as described in the file LICENSE.
Authors: Tobias Osborne
-/
import Mathlib.LinearAlgebra.TensorProduct.Basic
import Mathlib.Analysis.Normed.Module.Basic
import Mathlib.LinearAlgebra.Basis.VectorSpace
import Mathlib.RingTheory.Flat.Basic

/-!
# Cancellation Trick for Collinear Tensor Representations

We prove that for a binary tensor product `E âŠ—[ğ•œ] F` over a nontrivially normed field,
the **cross property** holds for all representations where the second-factor vectors
are collinear (scalar multiples of a single vector `wâ‚`). This result requires
**no Hahn-Banach hypothesis** (`h_bidual`).

## The Cancellation Trick

Given `v âŠ—â‚œ w = âˆ‘â±¼ vâ±¼ âŠ—â‚œ (Î±â±¼ â€¢ wâ‚)`:

1. **Bilinearity collapse**: The sum equals `(âˆ‘ Î±â±¼ â€¢ vâ±¼) âŠ—â‚œ wâ‚`.
2. **Triangle inequality** (correct direction!): `âˆ‘ |Î±â±¼| â€¢ â€–vâ±¼â€– â‰¥ â€–âˆ‘ Î±â±¼ â€¢ vâ±¼â€–`.
3. **Norm invariance**: From `v âŠ—â‚œ w = u âŠ—â‚œ wâ‚`, we get `â€–uâ€– â€¢ â€–wâ‚â€– = â€–vâ€– â€¢ â€–wâ€–`.

The key insight is that the tensor constraint forces residual cancellation,
making the triangle inequality go in the correct direction.

## Main results

* `ProjSeminorm.collinear_cost_ge`: The main theorem â€” the cost of any collinear
  representation is at least `â€–vâ€– * â€–wâ€–`.
-/

open scoped TensorProduct

namespace ProjSeminorm

variable {ğ•œ : Type*} [NontriviallyNormedField ğ•œ]
variable {E : Type*} [SeminormedAddCommGroup E] [NormedSpace ğ•œ E]
variable {F : Type*} [SeminormedAddCommGroup F] [NormedSpace ğ•œ F]

/-! ### Algebraic lemmas -/

/-- Over a field, `a âŠ—â‚œ b = 0` implies `a = 0` or `b = 0`.
This uses that modules over a `DivisionRing` are free (hence flat). -/
lemma tmul_eq_zero_of_field {a : E} {b : F} (h : a âŠ—â‚œ[ğ•œ] b = 0) :
    a = 0 âˆ¨ b = 0 := by
  by_contra hab
  push_neg at hab
  obtain âŸ¨ha, hbâŸ© := hab
  haveI : Module.Free ğ•œ E := Module.Free.of_divisionRing ğ•œ E
  have hinj : Function.Injective (LinearMap.toSpanSingleton ğ•œ F b) := by
    intro c d hcd
    simp only [LinearMap.toSpanSingleton_apply] at hcd
    exact smul_left_injective ğ•œ hb hcd
  have hlTinj := Module.Flat.lTensor_preserves_injective_linearMap
    (LinearMap.toSpanSingleton ğ•œ F b) hinj (M := E)
  have hmapped : LinearMap.lTensor E (LinearMap.toSpanSingleton ğ•œ F b)
      (a âŠ—â‚œ[ğ•œ] (1 : ğ•œ)) = a âŠ—â‚œ[ğ•œ] b := by
    simp [LinearMap.lTensor_tmul, LinearMap.toSpanSingleton_apply]
  have h1 : a âŠ—â‚œ[ğ•œ] (1 : ğ•œ) = 0 := hlTinj (by rw [hmapped, h, map_zero])
  apply ha
  have h2 := congr_arg (TensorProduct.rid ğ•œ E) h1
  simp only [map_zero] at h2
  simpa using h2

/-- Over a field, if `a âŠ—â‚œ b = 0` and `b â‰  0`, then `a = 0`. -/
lemma left_eq_zero_of_tmul_eq_zero {a : E} {b : F} (h : a âŠ—â‚œ[ğ•œ] b = 0) (hb : b â‰  0) :
    a = 0 := by
  exact (tmul_eq_zero_of_field h).resolve_right hb

/-! ### Algebraic dual functional -/

/-- For `v â‰  0` in a vector space over a nontrivially normed field,
there exists a linear functional `g` with `g v = 1`. -/
lemma exists_dual_eq_one (ğ•œ' : Type*) [NontriviallyNormedField ğ•œ']
    {V : Type*} [SeminormedAddCommGroup V] [NormedSpace ğ•œ' V]
    {v : V} (hv : v â‰  0) : âˆƒ g : V â†’â‚—[ğ•œ'] ğ•œ', g v = 1 := by
  haveI : Module.Free ğ•œ' V := Module.Free.of_divisionRing ğ•œ' V
  let B := Module.Free.chooseBasis ğ•œ' V
  have hBv : B.repr v â‰  0 :=
    fun h => hv (B.repr.injective (by rw [h, map_zero]))
  have : âˆƒ i, B.repr v i â‰  0 := by
    by_contra h; push_neg at h
    exact hBv (Finsupp.ext (fun i => by simp [h i]))
  obtain âŸ¨i, hiâŸ© := this
  exact âŸ¨(B.repr v i)â»Â¹ â€¢ B.coord i, by simp [hi]âŸ©

/-! ### Norm invariance for rank-1 tensors -/

/-- If `v âŠ—â‚œ w = u âŠ—â‚œ wâ‚` in a tensor product over a field, then
`â€–vâ€– * â€–wâ€– = â€–uâ€– * â€–wâ‚â€–`. Uses an algebraic functional to extract
the scalar relating the two representations. -/
theorem tmul_norm_product_eq {v u : E} {w wâ‚ : F}
    (h : v âŠ—â‚œ[ğ•œ] w = u âŠ—â‚œ[ğ•œ] wâ‚) :
    â€–vâ€– * â€–wâ€– = â€–uâ€– * â€–wâ‚â€– := by
  by_cases hv : v = 0
  Â· subst hv; simp only [TensorProduct.zero_tmul] at h
    rcases tmul_eq_zero_of_field h.symm with rfl | rfl <;> simp
  by_cases hwâ‚ : wâ‚ = 0
  Â· subst hwâ‚; simp only [TensorProduct.tmul_zero] at h
    rcases tmul_eq_zero_of_field h with rfl | rfl <;> simp
  -- v â‰  0, wâ‚ â‰  0. Get g : E â†’â‚— ğ•œ with g(v) = 1.
  obtain âŸ¨g, hgvâŸ© := exists_dual_eq_one ğ•œ hv
  -- Apply (g âŠ— id) then lid: g(v)â€¢w = g(u)â€¢wâ‚ in F
  have hlift : g v â€¢ w = g u â€¢ wâ‚ := by
    have hm := congr_arg ((TensorProduct.lid ğ•œ F).toLinearMap âˆ˜â‚—
      TensorProduct.map g (LinearMap.id : F â†’â‚—[ğ•œ] F)) h
    simpa [TensorProduct.map_tmul, TensorProduct.lid_tmul] using hm
  rw [hgv, one_smul] at hlift
  -- hlift : w = g u â€¢ wâ‚. Set c := g u.
  set c := g u
  -- (u - c â€¢ v) âŠ—â‚œ wâ‚ = 0, hence u = c â€¢ v
  have hsub : (u - c â€¢ v) âŠ—â‚œ[ğ•œ] wâ‚ = (0 : E âŠ—[ğ•œ] F) := by
    rw [TensorProduct.sub_tmul, TensorProduct.smul_tmul, â† hlift]
    simp [h]
  have hu_eq : u = c â€¢ v :=
    sub_eq_zero.mp (left_eq_zero_of_tmul_eq_zero hsub hwâ‚)
  -- â€–uâ€–*â€–wâ‚â€– = â€–câ€¢vâ€–*â€–wâ‚â€– = |c|*â€–vâ€–*â€–wâ‚â€– = â€–vâ€–*â€–câ€¢wâ‚â€– = â€–vâ€–*â€–wâ€–
  rw [hu_eq, hlift, norm_smul, norm_smul]; ring

/-! ### The cancellation trick: main theorem -/

/-- **Cancellation trick**: If `v âŠ—â‚œ w = âˆ‘â±¼ vâ±¼ âŠ—â‚œ (Î±â±¼ â€¢ wâ‚)` (collinear second factors),
then the representation cost satisfies `âˆ‘ â€–vâ±¼â€– * â€–Î±â±¼ â€¢ wâ‚â€– â‰¥ â€–vâ€– * â€–wâ€–`.

This is proved **without** any Hahn-Banach or bidual embedding hypothesis.
The key: bilinearity collapses the sum to `(âˆ‘ Î±â±¼ â€¢ vâ±¼) âŠ—â‚œ wâ‚`, the triangle
inequality applies in the correct direction, and norm invariance closes the proof. -/
theorem collinear_cost_ge {Î¹ : Type*} [Fintype Î¹]
    {v : E} {w : F} {v' : Î¹ â†’ E} {Î± : Î¹ â†’ ğ•œ} {wâ‚ : F}
    (h : v âŠ—â‚œ[ğ•œ] w = âˆ‘ j : Î¹, v' j âŠ—â‚œ[ğ•œ] (Î± j â€¢ wâ‚)) :
    â€–vâ€– * â€–wâ€– â‰¤ âˆ‘ j : Î¹, â€–v' jâ€– * â€–Î± j â€¢ wâ‚â€– := by
  -- Step 1: Bilinearity collapse
  -- âˆ‘ v'â±¼ âŠ—â‚œ (Î±â±¼ â€¢ wâ‚) = âˆ‘ (Î±â±¼ â€¢ v'â±¼) âŠ—â‚œ wâ‚ = (âˆ‘ Î±â±¼ â€¢ v'â±¼) âŠ—â‚œ wâ‚
  have hcollapse : v âŠ—â‚œ[ğ•œ] w = (âˆ‘ j, Î± j â€¢ v' j) âŠ—â‚œ[ğ•œ] wâ‚ := by
    rw [h]
    simp_rw [â† TensorProduct.smul_tmul]
    rw [â† TensorProduct.sum_tmul]
  -- Step 2: Norm invariance â€” â€–âˆ‘ Î±â±¼ â€¢ v'â±¼â€– * â€–wâ‚â€– = â€–vâ€– * â€–wâ€–
  have hnorm_eq := tmul_norm_product_eq hcollapse
  -- Step 3: Triangle inequality + norm_smul
  -- âˆ‘ â€–v'â±¼â€– * â€–Î±â±¼ â€¢ wâ‚â€– = âˆ‘ â€–v'â±¼â€– * (â€–Î±â±¼â€– * â€–wâ‚â€–) = â€–wâ‚â€– * âˆ‘ â€–Î±â±¼â€– * â€–v'â±¼â€–
  -- â‰¥ â€–wâ‚â€– * â€–âˆ‘ Î±â±¼ â€¢ v'â±¼â€– = â€–vâ€– * â€–wâ€–
  calc âˆ‘ j : Î¹, â€–v' jâ€– * â€–Î± j â€¢ wâ‚â€–
      = âˆ‘ j, â€–v' jâ€– * (â€–Î± jâ€– * â€–wâ‚â€–) := by simp_rw [norm_smul]
    _ = âˆ‘ j, â€–Î± jâ€– * â€–v' jâ€– * â€–wâ‚â€– := by congr 1; ext j; ring
    _ = (âˆ‘ j, â€–Î± jâ€– * â€–v' jâ€–) * â€–wâ‚â€– := (Finset.sum_mul ..).symm
    _ â‰¥ â€–âˆ‘ j, Î± j â€¢ v' jâ€– * â€–wâ‚â€– := by
        apply mul_le_mul_of_nonneg_right _ (norm_nonneg _)
        calc â€–âˆ‘ j, Î± j â€¢ v' jâ€–
            â‰¤ âˆ‘ j, â€–Î± j â€¢ v' jâ€– := norm_sum_le ..
          _ = âˆ‘ j, â€–Î± jâ€– * â€–v' jâ€– := by simp_rw [norm_smul]
    _ = â€–vâ€– * â€–wâ€– := hnorm_eq.symm

end ProjSeminorm
